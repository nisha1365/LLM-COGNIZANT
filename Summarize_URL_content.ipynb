{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbbiMHdFbicYrsDgFK/t+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/LLM-COGNIZANT/blob/main/Summarize_URL_content.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI GPT-3 API key\n",
        "#openai.api_key = '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'\n"
      ],
      "metadata": {
        "id": "Xra_adjyA69r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provide URL. Retrieve web content and summarize it."
      ],
      "metadata": {
        "id": "aoNH9JvkKPYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain unstructured tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzuUY-zdKQ5D",
        "outputId": "335298d3-efb1-4af3-e922-f890237ba0f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.345)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.11.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.9)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.5.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.8.0)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2023.6.15)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.5.2)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.8.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps :\n",
        "\n",
        "Load the URL using langchain\n",
        "\n",
        "Get the URL content as Document object\n",
        "\n",
        "Split the text\n",
        "\n",
        "Create Document objects of the split text\n",
        "\n",
        "Summarize the URL"
      ],
      "metadata": {
        "id": "z9Pk3rGlKX9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "i0_juRe9KS82"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load HTML documents from a given list of URLS Convert them to Document objects\n",
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "23bMKVwgKhDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import UnstructuredURLLoader"
      ],
      "metadata": {
        "id": "p4Zx8XrSKhaZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of urls as parameter to\n",
        "urls = [\"https://python.langchain.com/docs/modules/agents/\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "6MfDNZ1nKkMf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create instance of UnstructuredURLLoader class\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        ""
      ],
      "metadata": {
        "id": "eoVrhvHwKvfT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(type(loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-tbXawjKxyl",
        "outputId": "3241562d-e85b-44d0-ead7-4175837fa743"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain.document_loaders.url.UnstructuredURLLoader'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create list of Documents. One for each website content\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "bSlGeGnHKykK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(type(data),type(data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcR-gfg0K39V",
        "outputId": "ec068e5f-b788-439f-ee6d-b6abc1e4d1c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'langchain_core.documents.base.Document'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLE31P12K6fx",
        "outputId": "c7529e55-0615-426b-faaa-336b07a13a76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='\\n\\nModules\\n\\nAgents\\n\\nAgents\\n\\nThe core idea of agents is to use a language model to choose a sequence\\nof actions to take. In chains, a sequence of actions is hardcoded (in\\ncode). In agents, a language model is used as a reasoning engine to\\ndetermine which actions to take and in which order.\\n\\nConcepts\\u200b\\n\\nThere are several key components here:\\n\\nAgent\\u200b\\n\\nThis is the chain responsible for deciding what step to take next. This\\nis powered by a language model and a prompt. The inputs to this chain\\nare:\\n\\nTools: Descriptions of available tools\\n\\nUser input: The high level objective\\n\\nIntermediate steps: Any (action, tool output) pairs previously\\nexecuted in order to achieve the user input\\n\\nThe output is the next action(s) to take or the final response to send\\nto the user (AgentActions or AgentFinish). An action specifies a\\ntool and the input to that tool.\\n\\nDifferent agents have different prompting styles for reasoning,\\ndifferent ways of encoding inputs, and different ways of parsing the\\noutput. For a full list of built-in agents see agent\\ntypes. You can also easily build\\ncustom agents, which we show how to do in the Get started section\\nbelow.\\n\\nTools\\u200b\\n\\nTools are functions that an agent can invoke. There are two important\\ndesign considerations around tools:\\n\\nGiving the agent access to the right tools\\n\\nDescribing the tools in a way that is most helpful to the agent\\n\\nWithout thinking through both, you won’t be able to build a working\\nagent. If you don’t give the agent access to a correct set of tools, it\\nwill never be able to accomplish the objectives you give it. If you\\ndon’t describe the tools well, the agent won’t know how to use them\\nproperly.\\n\\nLangChain provides a wide set of built-in tools, but also makes it easy\\nto define your own (including custom descriptions). For a full list of\\nbuilt-in tools, see the tools integrations\\nsection\\n\\nToolkits\\u200b\\n\\nFor many common tasks, an agent will need a set of related tools. For\\nthis LangChain provides the concept of toolkits - groups of around 3-5\\ntools needed to accomplish specific objectives. For example, the GitHub\\ntoolkit has a tool for searching through GitHub issues, a tool for\\nreading a file, a tool for commenting, etc.\\n\\nLangChain provides a wide set of toolkits to get started. For a full\\nlist of built-in toolkits, see the toolkits integrations\\nsection\\n\\nAgentExecutor\\u200b\\n\\nThe agent executor is the runtime for an agent. This is what actually\\ncalls the agent, executes the actions it chooses, passes the action\\noutputs back to the agent, and repeats. In pseudocode, this looks\\nroughly like:\\n\\nnext_action\\n\\nagent\\n\\nget_action\\n\\nwhile\\n\\nnext_action\\n\\n!=\\n\\nAgentFinish\\n\\nobservation\\n\\nrun\\n\\nnext_action\\n\\nnext_action\\n\\nagent\\n\\nget_action\\n\\nnext_action\\n\\nobservation\\n\\nreturn\\n\\nnext_action\\n\\nWhile this may seem simple, there are several complexities this runtime\\nhandles for you, including:\\n\\nHandling cases where the agent selects a non-existent tool\\n\\nHandling cases where the tool errors\\n\\nHandling cases where the agent produces output that cannot be parsed\\ninto a tool invocation\\n\\nLogging and observability at all levels (agent decisions, tool\\ncalls) to stdout and/or to LangSmith.\\n\\nOther types of agent runtimes\\u200b\\n\\nThe AgentExecutor class is the main agent runtime supported by\\nLangChain. However, there are other, more experimental runtimes we also\\nsupport. These include:\\n\\nPlan-and-execute\\nAgent\\n\\nBaby AGI\\n\\nAuto GPT\\n\\nYou can also always create your own custom execution logic, which we\\nshow how to do below.\\n\\nGet started\\u200b\\n\\nTo best understand the agent framework, lets build an agent from scratch\\nusing LangChain Expression Language (LCEL). We’ll need to build the\\nagent itself, define custom tools, and run the agent and tools in a\\ncustom loop. At the end we’ll show how to use the standard LangChain\\nAgentExecutor to make execution easier.\\n\\nSome important terminology (and schema) to know:\\n\\nAgentAction: This is a dataclass that represents the action an\\nagent should take. It has a tool property (which is the name of\\nthe tool that should be invoked) and a tool_input property (the\\ninput to that tool)\\n\\nAgentFinish: This is a dataclass that signifies that the agent has\\nfinished and should return to the user. It has a return_values\\nparameter, which is a dictionary to return. It often only has one\\nkey - output - that is a string, and so often it is just this key\\nthat is returned.\\n\\nintermediate_steps: These represent previous agent actions and\\ncorresponding outputs that are passed around. These are important to\\npass to future iteration so the agent knows what work it has already\\ndone. This is typed as a List[Tuple[AgentAction, Any]]. Note that\\nobservation is currently left as type Any to be maximally\\nflexible. In practice, this is often a string.\\n\\nSetup: LangSmith\\u200b\\n\\nBy definition, agents take a self-determined, input-dependent sequence\\nof steps before returning a user-facing output. This makes debugging\\nthese systems particularly tricky, and observability particularly\\nimportant. LangSmith is especially useful for such\\ncases.\\n\\nWhen building with LangChain, any built-in agent or custom agent built\\nwith LCEL will automatically be traced in LangSmith. And if we use the\\nAgentExecutor, we’ll get full tracing of not only the agent planning\\nsteps but also the tool inputs and outputs.\\n\\nTo set up LangSmith we just need set the following environment\\nvariables:\\n\\nexport\\n\\nLANGCHAIN_TRACING_V2\\n\\n\"true\"\\n\\nexport\\n\\nLANGCHAIN_API_KEY\\n\\n\"<your-api-key>\"\\n\\nDefine the agent\\u200b\\n\\nWe first need to create our agent. This is the chain responsible for\\ndetermining what action to take next.\\n\\nIn this example, we will use OpenAI Function Calling to create this\\nagent. This is generally the most reliable way to create agents.\\n\\nFor this guide, we will construct a custom agent that has access to a\\ncustom tool. We are choosing this example because for most real world\\nuse cases you will NEED to customize either the agent or the tools.\\nWe’ll create a simple tool that computes the length of a word. This is\\nuseful because it’s actually something LLMs can mess up due to\\ntokenization. We will first create it WITHOUT memory, but we will then\\nshow how to add memory in. Memory is needed to enable conversation.\\n\\nFirst, let’s load the language model we’re going to use to control the\\nagent.\\n\\nfrom\\n\\nlangchain\\n\\nchat_models\\n\\nimport\\n\\nChatOpenAI\\n\\nllm\\n\\nChatOpenAI\\n\\nmodel\\n\\n\"gpt-3.5-turbo\"\\n\\ntemperature\\n\\nWe can see that it struggles to count the letters in the string “educa”.\\n\\nllm\\n\\ninvoke\\n\\n\"how many letters in the word educa?\"\\n\\nAIMessage(content=\\'There are 6 letters in the word \"educa\".\\')\\n\\nNext, let’s define some tools to use. Let’s write a really simple Python\\nfunction to calculate the length of a word that is passed in.\\n\\nfrom\\n\\nlangchain\\n\\nagents\\n\\nimport\\n\\ntool\\n\\n@tool\\n\\ndef\\n\\nget_word_length\\n\\nword\\n\\nstr\\n\\nint\\n\\n\"\"\"Returns the length of a word.\"\"\"\\n\\nreturn\\n\\nlen\\n\\nword\\n\\ntools\\n\\nget_word_length\\n\\nNow let us create the prompt. Because OpenAI Function Calling is\\nfinetuned for tool usage, we hardly need any instructions on how to\\nreason, or how to output format. We will just have two input variables:\\ninput and agent_scratchpad. input should be a string containing\\nthe user objective. agent_scratchpad should be a sequence of messages\\nthat contains the previous agent tool invocations and the corresponding\\ntool outputs.\\n\\nfrom\\n\\nlangchain\\n\\nprompts\\n\\nimport\\n\\nChatPromptTemplate\\n\\nMessagesPlaceholder\\n\\nprompt\\n\\nChatPromptTemplate\\n\\nfrom_messages\\n\\n\"system\"\\n\\n\"You are very powerful assistant, but bad at calculating lengths of words.\"\\n\\n\"user\"\\n\\n\"{input}\"\\n\\nMessagesPlaceholder\\n\\nvariable_name\\n\\n\"agent_scratchpad\"\\n\\nHow does the agent know what tools it can use? In this case we’re\\nrelying on OpenAI function calling LLMs, which take functions as a\\nseparate argument and have been specifically trained to know when to\\ninvoke those functions.\\n\\nTo pass in our tools to the agent, we just need to format them to the\\nOpenAI function format and pass them to our model. (By bind-ing the\\nfunctions, we’re making sure that they’re passed in each time the model\\nis invoked.)\\n\\nfrom\\n\\nlangchain\\n\\ntools\\n\\nrender\\n\\nimport\\n\\nformat_tool_to_openai_function\\n\\nllm_with_tools\\n\\nllm\\n\\nbind\\n\\nfunctions\\n\\nformat_tool_to_openai_function\\n\\nfor\\n\\nin\\n\\ntools\\n\\nPutting those pieces together, we can now create the agent. We will\\nimport two last utility functions: a component for formatting\\nintermediate steps (agent action, tool output pairs) to input messages\\nthat can be sent to the model, and a component for converting the output\\nmessage into an agent action/agent finish.\\n\\nfrom\\n\\nlangchain\\n\\nagents\\n\\nformat_scratchpad\\n\\nimport\\n\\nformat_to_openai_function_messages\\n\\nfrom\\n\\nlangchain\\n\\nagents\\n\\noutput_parsers\\n\\nimport\\n\\nOpenAIFunctionsAgentOutputParser\\n\\nagent\\n\\n\"input\"\\n\\nlambda\\n\\n\"input\"\\n\\n\"agent_scratchpad\"\\n\\nlambda\\n\\nformat_to_openai_function_messages\\n\\n\"intermediate_steps\"\\n\\nprompt\\n\\nllm_with_tools\\n\\nOpenAIFunctionsAgentOutputParser\\n\\nNow that we have our agent, let’s play around with it! Let’s pass in a\\nsimple question and empty intermediate steps and see what it returns:\\n\\nagent\\n\\ninvoke\\n\\n\"input\"\\n\\n\"how many letters in the word educa?\"\\n\\n\"intermediate_steps\"\\n\\nAgentActionMessageLog(tool=\\'get_word_length\\', tool_input={\\'word\\': \\'educa\\'}, log=\"\\\\nInvoking: `get_word_length` with `{\\'word\\': \\'educa\\'}`\\\\n\\\\n\\\\n\", message_log=[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'{\\\\n  \"word\": \"educa\"\\\\n}\\', \\'name\\': \\'get_word_length\\'}})])\\n\\nWe can see that it responds with an AgentAction to take (it’s actually\\nan AgentActionMessageLog - a subclass of AgentAction which also\\ntracks the full message log).\\n\\nIf we’ve set up LangSmith, we’ll see a trace that let’s us inspect the\\ninput and output to each step in the sequence:\\nhttps://smith.langchain.com/public/04110122-01a8-413c-8cd0-b4df6eefa4b7/r\\n\\nDefine the runtime\\u200b\\n\\nSo this is just the first step - now we need to write a runtime for\\nthis. The simplest one is just one that continuously loops, calling the\\nagent, then taking the action, and repeating until an AgentFinish is\\nreturned. Let’s code that up below:\\n\\nfrom\\n\\nlangchain\\n\\nschema\\n\\nagent\\n\\nimport\\n\\nAgentFinish\\n\\nuser_input\\n\\n\"how many letters in the word educa?\"\\n\\nintermediate_steps\\n\\nwhile\\n\\nTrue\\n\\noutput\\n\\nagent\\n\\ninvoke\\n\\n\"input\"\\n\\nuser_input\\n\\n\"intermediate_steps\"\\n\\nintermediate_steps\\n\\nif\\n\\nisinstance\\n\\noutput\\n\\nAgentFinish\\n\\nfinal_result\\n\\noutput\\n\\nreturn_values\\n\\n\"output\"\\n\\nbreak\\n\\nelse\\n\\nprint\\n\\nf\"TOOL NAME:\\n\\noutput\\n\\ntool\\n\\nprint\\n\\nf\"TOOL INPUT:\\n\\noutput\\n\\ntool_input\\n\\ntool\\n\\n\"get_word_length\"\\n\\nget_word_length\\n\\noutput\\n\\ntool\\n\\nobservation\\n\\ntool\\n\\nrun\\n\\noutput\\n\\ntool_input\\n\\nintermediate_steps\\n\\nappend\\n\\noutput\\n\\nobservation\\n\\nprint\\n\\nfinal_result\\n\\nTOOL NAME: get_word_length\\n\\nTOOL INPUT: {\\'word\\': \\'educa\\'}\\n\\nThere are 5 letters in the word \"educa\".\\n\\nWoo! It’s working.\\n\\nUsing AgentExecutor\\u200b\\n\\nTo simplify this a bit, we can import and use the AgentExecutor class.\\nThis bundles up all of the above and adds in error handling, early\\nstopping, tracing, and other quality-of-life improvements that reduce\\nsafeguards you need to write.\\n\\nfrom\\n\\nlangchain\\n\\nagents\\n\\nimport\\n\\nAgentExecutor\\n\\nagent_executor\\n\\nAgentExecutor\\n\\nagent\\n\\nagent\\n\\ntools\\n\\ntools\\n\\nverbose\\n\\nTrue\\n\\nNow let’s test it out!\\n\\nagent_executor\\n\\ninvoke\\n\\n\"input\"\\n\\n\"how many letters in the word educa?\"\\n\\n> Entering new AgentExecutor chain...\\n\\nInvoking: `get_word_length` with `{\\'word\\': \\'educa\\'}`\\n\\n5There are 5 letters in the word \"educa\".\\n\\n> Finished chain.\\n\\n{\\'input\\': \\'how many letters in the word educa?\\',\\n\\n\\'output\\': \\'There are 5 letters in the word \"educa\".\\'}\\n\\nAnd looking at the trace, we can see that all of our agent calls and\\ntool invocations are automatically logged:\\nhttps://smith.langchain.com/public/957b7e26-bef8-4b5b-9ca3-4b4f1c96d501/r\\n\\nAdding memory\\u200b\\n\\nThis is great - we have an agent! However, this agent is stateless - it\\ndoesn’t remember anything about previous interactions. This means you\\ncan’t ask follow up questions easily. Let’s fix that by adding in\\nmemory.\\n\\nIn order to do this, we need to do two things:\\n\\nAdd a place for memory variables to go in the prompt\\n\\nKeep track of the chat history\\n\\nFirst, let’s add a place for memory in the prompt. We do this by adding\\na placeholder for messages with the key \"chat_history\". Notice that we\\nput this ABOVE the new user input (to follow the conversation flow).\\n\\nfrom\\n\\nlangchain\\n\\nprompts\\n\\nimport\\n\\nMessagesPlaceholder\\n\\nMEMORY_KEY\\n\\n\"chat_history\"\\n\\nprompt\\n\\nChatPromptTemplate\\n\\nfrom_messages\\n\\n\"system\"\\n\\n\"You are very powerful assistant, but bad at calculating lengths of words.\"\\n\\nMessagesPlaceholder\\n\\nvariable_name\\n\\nMEMORY_KEY\\n\\n\"user\"\\n\\n\"{input}\"\\n\\nMessagesPlaceholder\\n\\nvariable_name\\n\\n\"agent_scratchpad\"\\n\\nWe can then set up a list to track the chat history\\n\\nfrom\\n\\nlangchain\\n\\nschema\\n\\nmessages\\n\\nimport\\n\\nAIMessage\\n\\nHumanMessage\\n\\nchat_history\\n\\nWe can then put it all together!\\n\\nagent\\n\\n\"input\"\\n\\nlambda\\n\\n\"input\"\\n\\n\"agent_scratchpad\"\\n\\nlambda\\n\\nformat_to_openai_function_messages\\n\\n\"intermediate_steps\"\\n\\n\"chat_history\"\\n\\nlambda\\n\\n\"chat_history\"\\n\\nprompt\\n\\nllm_with_tools\\n\\nOpenAIFunctionsAgentOutputParser\\n\\nagent_executor\\n\\nAgentExecutor\\n\\nagent\\n\\nagent\\n\\ntools\\n\\ntools\\n\\nverbose\\n\\nTrue\\n\\nWhen running, we now need to track the inputs and outputs as chat\\nhistory\\n\\ninput1\\n\\n\"how many letters in the word educa?\"\\n\\nresult\\n\\nagent_executor\\n\\ninvoke\\n\\n\"input\"\\n\\ninput1\\n\\n\"chat_history\"\\n\\nchat_history\\n\\nchat_history\\n\\nextend\\n\\nHumanMessage\\n\\ncontent\\n\\ninput1\\n\\nAIMessage\\n\\ncontent\\n\\nresult\\n\\n\"output\"\\n\\nagent_executor\\n\\ninvoke\\n\\n\"input\"\\n\\n\"is that a real word?\"\\n\\n\"chat_history\"\\n\\nchat_history\\n\\n> Entering new AgentExecutor chain...\\n\\nInvoking: `get_word_length` with `{\\'word\\': \\'educa\\'}`\\n\\n5There are 5 letters in the word \"educa\".\\n\\n> Finished chain.\\n\\n> Entering new AgentExecutor chain...\\n\\nNo, \"educa\" is not a real word in English.\\n\\n> Finished chain.\\n\\n{\\'input\\': \\'is that a real word?\\',\\n\\n\\'chat_history\\': [HumanMessage(content=\\'how many letters in the word educa?\\'),\\n\\nAIMessage(content=\\'There are 5 letters in the word \"educa\".\\')],\\n\\n\\'output\\': \\'No, \"educa\" is not a real word in English.\\'}\\n\\nHere’s the LangSmith trace:\\nhttps://smith.langchain.com/public/1e1b7e07-3220-4a6c-8a1e-f04182a755b3/r\\n\\nNext Steps\\u200b\\n\\nAwesome! You’ve now run your first end-to-end agent. To dive deeper, you\\ncan:\\n\\nCheck out all the different agent\\ntypes supported\\n\\nLearn all the controls for\\nAgentExecutor\\n\\nExplore the how-to’s of tools and all\\nthe tool integrations\\n\\nSee a full list of all the off-the-shelf\\ntoolkits we provide\\n\\nPreviousIndexing\\n\\nNextAgent Types\\n\\nConceptsAgentToolsToolkitsAgentExecutorOther types of agent runtimes\\n\\nGet startedSetup: LangSmithDefine the agentDefine the runtimeUsing AgentExecutorAdding memory\\n\\nNext Steps', metadata={'source': 'https://python.langchain.com/docs/modules/agents/'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of Document objects\n",
        "\n",
        "page_content : str\n",
        "\n",
        "metadata : Dictionary"
      ],
      "metadata": {
        "id": "JuZonnJxMav_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data[0].page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA3wlvOvMdfX",
        "outputId": "6805b4f2-9f4c-408b-d0a8-9c332f27f981"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Modules\n",
            "\n",
            "Agents\n",
            "\n",
            "Agents\n",
            "\n",
            "The core idea of agents is to use a language model to choose a sequence\n",
            "of actions to take. In chains, a sequence of actions is hardcoded (in\n",
            "code). In agents, a language model is used as a reasoning engine to\n",
            "determine which actions to take and in which order.\n",
            "\n",
            "Concepts​\n",
            "\n",
            "There are several key components here:\n",
            "\n",
            "Agent​\n",
            "\n",
            "This is the chain responsible for deciding what step to take next. This\n",
            "is powered by a language model and a prompt. The inputs to this chain\n",
            "are:\n",
            "\n",
            "Tools: Descriptions of available tools\n",
            "\n",
            "User input: The high level objective\n",
            "\n",
            "Intermediate steps: Any (action, tool output) pairs previously\n",
            "executed in order to achieve the user input\n",
            "\n",
            "The output is the next action(s) to take or the final response to send\n",
            "to the user (AgentActions or AgentFinish). An action specifies a\n",
            "tool and the input to that tool.\n",
            "\n",
            "Different agents have different prompting styles for reasoning,\n",
            "different ways of encoding inputs, and different ways of parsing the\n",
            "output. For a full list of built-in agents see agent\n",
            "types. You can also easily build\n",
            "custom agents, which we show how to do in the Get started section\n",
            "below.\n",
            "\n",
            "Tools​\n",
            "\n",
            "Tools are functions that an agent can invoke. There are two important\n",
            "design considerations around tools:\n",
            "\n",
            "Giving the agent access to the right tools\n",
            "\n",
            "Describing the tools in a way that is most helpful to the agent\n",
            "\n",
            "Without thinking through both, you won’t be able to build a working\n",
            "agent. If you don’t give the agent access to a correct set of tools, it\n",
            "will never be able to accomplish the objectives you give it. If you\n",
            "don’t describe the tools well, the agent won’t know how to use them\n",
            "properly.\n",
            "\n",
            "LangChain provides a wide set of built-in tools, but also makes it easy\n",
            "to define your own (including custom descriptions). For a full list of\n",
            "built-in tools, see the tools integrations\n",
            "section\n",
            "\n",
            "Toolkits​\n",
            "\n",
            "For many common tasks, an agent will need a set of related tools. For\n",
            "this LangChain provides the concept of toolkits - groups of around 3-5\n",
            "tools needed to accomplish specific objectives. For example, the GitHub\n",
            "toolkit has a tool for searching through GitHub issues, a tool for\n",
            "reading a file, a tool for commenting, etc.\n",
            "\n",
            "LangChain provides a wide set of toolkits to get started. For a full\n",
            "list of built-in toolkits, see the toolkits integrations\n",
            "section\n",
            "\n",
            "AgentExecutor​\n",
            "\n",
            "The agent executor is the runtime for an agent. This is what actually\n",
            "calls the agent, executes the actions it chooses, passes the action\n",
            "outputs back to the agent, and repeats. In pseudocode, this looks\n",
            "roughly like:\n",
            "\n",
            "next_action\n",
            "\n",
            "agent\n",
            "\n",
            "get_action\n",
            "\n",
            "while\n",
            "\n",
            "next_action\n",
            "\n",
            "!=\n",
            "\n",
            "AgentFinish\n",
            "\n",
            "observation\n",
            "\n",
            "run\n",
            "\n",
            "next_action\n",
            "\n",
            "next_action\n",
            "\n",
            "agent\n",
            "\n",
            "get_action\n",
            "\n",
            "next_action\n",
            "\n",
            "observation\n",
            "\n",
            "return\n",
            "\n",
            "next_action\n",
            "\n",
            "While this may seem simple, there are several complexities this runtime\n",
            "handles for you, including:\n",
            "\n",
            "Handling cases where the agent selects a non-existent tool\n",
            "\n",
            "Handling cases where the tool errors\n",
            "\n",
            "Handling cases where the agent produces output that cannot be parsed\n",
            "into a tool invocation\n",
            "\n",
            "Logging and observability at all levels (agent decisions, tool\n",
            "calls) to stdout and/or to LangSmith.\n",
            "\n",
            "Other types of agent runtimes​\n",
            "\n",
            "The AgentExecutor class is the main agent runtime supported by\n",
            "LangChain. However, there are other, more experimental runtimes we also\n",
            "support. These include:\n",
            "\n",
            "Plan-and-execute\n",
            "Agent\n",
            "\n",
            "Baby AGI\n",
            "\n",
            "Auto GPT\n",
            "\n",
            "You can also always create your own custom execution logic, which we\n",
            "show how to do below.\n",
            "\n",
            "Get started​\n",
            "\n",
            "To best understand the agent framework, lets build an agent from scratch\n",
            "using LangChain Expression Language (LCEL). We’ll need to build the\n",
            "agent itself, define custom tools, and run the agent and tools in a\n",
            "custom loop. At the end we’ll show how to use the standard LangChain\n",
            "AgentExecutor to make execution easier.\n",
            "\n",
            "Some important terminology (and schema) to know:\n",
            "\n",
            "AgentAction: This is a dataclass that represents the action an\n",
            "agent should take. It has a tool property (which is the name of\n",
            "the tool that should be invoked) and a tool_input property (the\n",
            "input to that tool)\n",
            "\n",
            "AgentFinish: This is a dataclass that signifies that the agent has\n",
            "finished and should return to the user. It has a return_values\n",
            "parameter, which is a dictionary to return. It often only has one\n",
            "key - output - that is a string, and so often it is just this key\n",
            "that is returned.\n",
            "\n",
            "intermediate_steps: These represent previous agent actions and\n",
            "corresponding outputs that are passed around. These are important to\n",
            "pass to future iteration so the agent knows what work it has already\n",
            "done. This is typed as a List[Tuple[AgentAction, Any]]. Note that\n",
            "observation is currently left as type Any to be maximally\n",
            "flexible. In practice, this is often a string.\n",
            "\n",
            "Setup: LangSmith​\n",
            "\n",
            "By definition, agents take a self-determined, input-dependent sequence\n",
            "of steps before returning a user-facing output. This makes debugging\n",
            "these systems particularly tricky, and observability particularly\n",
            "important. LangSmith is especially useful for such\n",
            "cases.\n",
            "\n",
            "When building with LangChain, any built-in agent or custom agent built\n",
            "with LCEL will automatically be traced in LangSmith. And if we use the\n",
            "AgentExecutor, we’ll get full tracing of not only the agent planning\n",
            "steps but also the tool inputs and outputs.\n",
            "\n",
            "To set up LangSmith we just need set the following environment\n",
            "variables:\n",
            "\n",
            "export\n",
            "\n",
            "LANGCHAIN_TRACING_V2\n",
            "\n",
            "\"true\"\n",
            "\n",
            "export\n",
            "\n",
            "LANGCHAIN_API_KEY\n",
            "\n",
            "\"<your-api-key>\"\n",
            "\n",
            "Define the agent​\n",
            "\n",
            "We first need to create our agent. This is the chain responsible for\n",
            "determining what action to take next.\n",
            "\n",
            "In this example, we will use OpenAI Function Calling to create this\n",
            "agent. This is generally the most reliable way to create agents.\n",
            "\n",
            "For this guide, we will construct a custom agent that has access to a\n",
            "custom tool. We are choosing this example because for most real world\n",
            "use cases you will NEED to customize either the agent or the tools.\n",
            "We’ll create a simple tool that computes the length of a word. This is\n",
            "useful because it’s actually something LLMs can mess up due to\n",
            "tokenization. We will first create it WITHOUT memory, but we will then\n",
            "show how to add memory in. Memory is needed to enable conversation.\n",
            "\n",
            "First, let’s load the language model we’re going to use to control the\n",
            "agent.\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "chat_models\n",
            "\n",
            "import\n",
            "\n",
            "ChatOpenAI\n",
            "\n",
            "llm\n",
            "\n",
            "ChatOpenAI\n",
            "\n",
            "model\n",
            "\n",
            "\"gpt-3.5-turbo\"\n",
            "\n",
            "temperature\n",
            "\n",
            "We can see that it struggles to count the letters in the string “educa”.\n",
            "\n",
            "llm\n",
            "\n",
            "invoke\n",
            "\n",
            "\"how many letters in the word educa?\"\n",
            "\n",
            "AIMessage(content='There are 6 letters in the word \"educa\".')\n",
            "\n",
            "Next, let’s define some tools to use. Let’s write a really simple Python\n",
            "function to calculate the length of a word that is passed in.\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "agents\n",
            "\n",
            "import\n",
            "\n",
            "tool\n",
            "\n",
            "@tool\n",
            "\n",
            "def\n",
            "\n",
            "get_word_length\n",
            "\n",
            "word\n",
            "\n",
            "str\n",
            "\n",
            "int\n",
            "\n",
            "\"\"\"Returns the length of a word.\"\"\"\n",
            "\n",
            "return\n",
            "\n",
            "len\n",
            "\n",
            "word\n",
            "\n",
            "tools\n",
            "\n",
            "get_word_length\n",
            "\n",
            "Now let us create the prompt. Because OpenAI Function Calling is\n",
            "finetuned for tool usage, we hardly need any instructions on how to\n",
            "reason, or how to output format. We will just have two input variables:\n",
            "input and agent_scratchpad. input should be a string containing\n",
            "the user objective. agent_scratchpad should be a sequence of messages\n",
            "that contains the previous agent tool invocations and the corresponding\n",
            "tool outputs.\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "prompts\n",
            "\n",
            "import\n",
            "\n",
            "ChatPromptTemplate\n",
            "\n",
            "MessagesPlaceholder\n",
            "\n",
            "prompt\n",
            "\n",
            "ChatPromptTemplate\n",
            "\n",
            "from_messages\n",
            "\n",
            "\"system\"\n",
            "\n",
            "\"You are very powerful assistant, but bad at calculating lengths of words.\"\n",
            "\n",
            "\"user\"\n",
            "\n",
            "\"{input}\"\n",
            "\n",
            "MessagesPlaceholder\n",
            "\n",
            "variable_name\n",
            "\n",
            "\"agent_scratchpad\"\n",
            "\n",
            "How does the agent know what tools it can use? In this case we’re\n",
            "relying on OpenAI function calling LLMs, which take functions as a\n",
            "separate argument and have been specifically trained to know when to\n",
            "invoke those functions.\n",
            "\n",
            "To pass in our tools to the agent, we just need to format them to the\n",
            "OpenAI function format and pass them to our model. (By bind-ing the\n",
            "functions, we’re making sure that they’re passed in each time the model\n",
            "is invoked.)\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "tools\n",
            "\n",
            "render\n",
            "\n",
            "import\n",
            "\n",
            "format_tool_to_openai_function\n",
            "\n",
            "llm_with_tools\n",
            "\n",
            "llm\n",
            "\n",
            "bind\n",
            "\n",
            "functions\n",
            "\n",
            "format_tool_to_openai_function\n",
            "\n",
            "for\n",
            "\n",
            "in\n",
            "\n",
            "tools\n",
            "\n",
            "Putting those pieces together, we can now create the agent. We will\n",
            "import two last utility functions: a component for formatting\n",
            "intermediate steps (agent action, tool output pairs) to input messages\n",
            "that can be sent to the model, and a component for converting the output\n",
            "message into an agent action/agent finish.\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "agents\n",
            "\n",
            "format_scratchpad\n",
            "\n",
            "import\n",
            "\n",
            "format_to_openai_function_messages\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "agents\n",
            "\n",
            "output_parsers\n",
            "\n",
            "import\n",
            "\n",
            "OpenAIFunctionsAgentOutputParser\n",
            "\n",
            "agent\n",
            "\n",
            "\"input\"\n",
            "\n",
            "lambda\n",
            "\n",
            "\"input\"\n",
            "\n",
            "\"agent_scratchpad\"\n",
            "\n",
            "lambda\n",
            "\n",
            "format_to_openai_function_messages\n",
            "\n",
            "\"intermediate_steps\"\n",
            "\n",
            "prompt\n",
            "\n",
            "llm_with_tools\n",
            "\n",
            "OpenAIFunctionsAgentOutputParser\n",
            "\n",
            "Now that we have our agent, let’s play around with it! Let’s pass in a\n",
            "simple question and empty intermediate steps and see what it returns:\n",
            "\n",
            "agent\n",
            "\n",
            "invoke\n",
            "\n",
            "\"input\"\n",
            "\n",
            "\"how many letters in the word educa?\"\n",
            "\n",
            "\"intermediate_steps\"\n",
            "\n",
            "AgentActionMessageLog(tool='get_word_length', tool_input={'word': 'educa'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'educa'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"word\": \"educa\"\\n}', 'name': 'get_word_length'}})])\n",
            "\n",
            "We can see that it responds with an AgentAction to take (it’s actually\n",
            "an AgentActionMessageLog - a subclass of AgentAction which also\n",
            "tracks the full message log).\n",
            "\n",
            "If we’ve set up LangSmith, we’ll see a trace that let’s us inspect the\n",
            "input and output to each step in the sequence:\n",
            "https://smith.langchain.com/public/04110122-01a8-413c-8cd0-b4df6eefa4b7/r\n",
            "\n",
            "Define the runtime​\n",
            "\n",
            "So this is just the first step - now we need to write a runtime for\n",
            "this. The simplest one is just one that continuously loops, calling the\n",
            "agent, then taking the action, and repeating until an AgentFinish is\n",
            "returned. Let’s code that up below:\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "schema\n",
            "\n",
            "agent\n",
            "\n",
            "import\n",
            "\n",
            "AgentFinish\n",
            "\n",
            "user_input\n",
            "\n",
            "\"how many letters in the word educa?\"\n",
            "\n",
            "intermediate_steps\n",
            "\n",
            "while\n",
            "\n",
            "True\n",
            "\n",
            "output\n",
            "\n",
            "agent\n",
            "\n",
            "invoke\n",
            "\n",
            "\"input\"\n",
            "\n",
            "user_input\n",
            "\n",
            "\"intermediate_steps\"\n",
            "\n",
            "intermediate_steps\n",
            "\n",
            "if\n",
            "\n",
            "isinstance\n",
            "\n",
            "output\n",
            "\n",
            "AgentFinish\n",
            "\n",
            "final_result\n",
            "\n",
            "output\n",
            "\n",
            "return_values\n",
            "\n",
            "\"output\"\n",
            "\n",
            "break\n",
            "\n",
            "else\n",
            "\n",
            "print\n",
            "\n",
            "f\"TOOL NAME:\n",
            "\n",
            "output\n",
            "\n",
            "tool\n",
            "\n",
            "print\n",
            "\n",
            "f\"TOOL INPUT:\n",
            "\n",
            "output\n",
            "\n",
            "tool_input\n",
            "\n",
            "tool\n",
            "\n",
            "\"get_word_length\"\n",
            "\n",
            "get_word_length\n",
            "\n",
            "output\n",
            "\n",
            "tool\n",
            "\n",
            "observation\n",
            "\n",
            "tool\n",
            "\n",
            "run\n",
            "\n",
            "output\n",
            "\n",
            "tool_input\n",
            "\n",
            "intermediate_steps\n",
            "\n",
            "append\n",
            "\n",
            "output\n",
            "\n",
            "observation\n",
            "\n",
            "print\n",
            "\n",
            "final_result\n",
            "\n",
            "TOOL NAME: get_word_length\n",
            "\n",
            "TOOL INPUT: {'word': 'educa'}\n",
            "\n",
            "There are 5 letters in the word \"educa\".\n",
            "\n",
            "Woo! It’s working.\n",
            "\n",
            "Using AgentExecutor​\n",
            "\n",
            "To simplify this a bit, we can import and use the AgentExecutor class.\n",
            "This bundles up all of the above and adds in error handling, early\n",
            "stopping, tracing, and other quality-of-life improvements that reduce\n",
            "safeguards you need to write.\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "agents\n",
            "\n",
            "import\n",
            "\n",
            "AgentExecutor\n",
            "\n",
            "agent_executor\n",
            "\n",
            "AgentExecutor\n",
            "\n",
            "agent\n",
            "\n",
            "agent\n",
            "\n",
            "tools\n",
            "\n",
            "tools\n",
            "\n",
            "verbose\n",
            "\n",
            "True\n",
            "\n",
            "Now let’s test it out!\n",
            "\n",
            "agent_executor\n",
            "\n",
            "invoke\n",
            "\n",
            "\"input\"\n",
            "\n",
            "\"how many letters in the word educa?\"\n",
            "\n",
            "> Entering new AgentExecutor chain...\n",
            "\n",
            "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
            "\n",
            "5There are 5 letters in the word \"educa\".\n",
            "\n",
            "> Finished chain.\n",
            "\n",
            "{'input': 'how many letters in the word educa?',\n",
            "\n",
            "'output': 'There are 5 letters in the word \"educa\".'}\n",
            "\n",
            "And looking at the trace, we can see that all of our agent calls and\n",
            "tool invocations are automatically logged:\n",
            "https://smith.langchain.com/public/957b7e26-bef8-4b5b-9ca3-4b4f1c96d501/r\n",
            "\n",
            "Adding memory​\n",
            "\n",
            "This is great - we have an agent! However, this agent is stateless - it\n",
            "doesn’t remember anything about previous interactions. This means you\n",
            "can’t ask follow up questions easily. Let’s fix that by adding in\n",
            "memory.\n",
            "\n",
            "In order to do this, we need to do two things:\n",
            "\n",
            "Add a place for memory variables to go in the prompt\n",
            "\n",
            "Keep track of the chat history\n",
            "\n",
            "First, let’s add a place for memory in the prompt. We do this by adding\n",
            "a placeholder for messages with the key \"chat_history\". Notice that we\n",
            "put this ABOVE the new user input (to follow the conversation flow).\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "prompts\n",
            "\n",
            "import\n",
            "\n",
            "MessagesPlaceholder\n",
            "\n",
            "MEMORY_KEY\n",
            "\n",
            "\"chat_history\"\n",
            "\n",
            "prompt\n",
            "\n",
            "ChatPromptTemplate\n",
            "\n",
            "from_messages\n",
            "\n",
            "\"system\"\n",
            "\n",
            "\"You are very powerful assistant, but bad at calculating lengths of words.\"\n",
            "\n",
            "MessagesPlaceholder\n",
            "\n",
            "variable_name\n",
            "\n",
            "MEMORY_KEY\n",
            "\n",
            "\"user\"\n",
            "\n",
            "\"{input}\"\n",
            "\n",
            "MessagesPlaceholder\n",
            "\n",
            "variable_name\n",
            "\n",
            "\"agent_scratchpad\"\n",
            "\n",
            "We can then set up a list to track the chat history\n",
            "\n",
            "from\n",
            "\n",
            "langchain\n",
            "\n",
            "schema\n",
            "\n",
            "messages\n",
            "\n",
            "import\n",
            "\n",
            "AIMessage\n",
            "\n",
            "HumanMessage\n",
            "\n",
            "chat_history\n",
            "\n",
            "We can then put it all together!\n",
            "\n",
            "agent\n",
            "\n",
            "\"input\"\n",
            "\n",
            "lambda\n",
            "\n",
            "\"input\"\n",
            "\n",
            "\"agent_scratchpad\"\n",
            "\n",
            "lambda\n",
            "\n",
            "format_to_openai_function_messages\n",
            "\n",
            "\"intermediate_steps\"\n",
            "\n",
            "\"chat_history\"\n",
            "\n",
            "lambda\n",
            "\n",
            "\"chat_history\"\n",
            "\n",
            "prompt\n",
            "\n",
            "llm_with_tools\n",
            "\n",
            "OpenAIFunctionsAgentOutputParser\n",
            "\n",
            "agent_executor\n",
            "\n",
            "AgentExecutor\n",
            "\n",
            "agent\n",
            "\n",
            "agent\n",
            "\n",
            "tools\n",
            "\n",
            "tools\n",
            "\n",
            "verbose\n",
            "\n",
            "True\n",
            "\n",
            "When running, we now need to track the inputs and outputs as chat\n",
            "history\n",
            "\n",
            "input1\n",
            "\n",
            "\"how many letters in the word educa?\"\n",
            "\n",
            "result\n",
            "\n",
            "agent_executor\n",
            "\n",
            "invoke\n",
            "\n",
            "\"input\"\n",
            "\n",
            "input1\n",
            "\n",
            "\"chat_history\"\n",
            "\n",
            "chat_history\n",
            "\n",
            "chat_history\n",
            "\n",
            "extend\n",
            "\n",
            "HumanMessage\n",
            "\n",
            "content\n",
            "\n",
            "input1\n",
            "\n",
            "AIMessage\n",
            "\n",
            "content\n",
            "\n",
            "result\n",
            "\n",
            "\"output\"\n",
            "\n",
            "agent_executor\n",
            "\n",
            "invoke\n",
            "\n",
            "\"input\"\n",
            "\n",
            "\"is that a real word?\"\n",
            "\n",
            "\"chat_history\"\n",
            "\n",
            "chat_history\n",
            "\n",
            "> Entering new AgentExecutor chain...\n",
            "\n",
            "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
            "\n",
            "5There are 5 letters in the word \"educa\".\n",
            "\n",
            "> Finished chain.\n",
            "\n",
            "> Entering new AgentExecutor chain...\n",
            "\n",
            "No, \"educa\" is not a real word in English.\n",
            "\n",
            "> Finished chain.\n",
            "\n",
            "{'input': 'is that a real word?',\n",
            "\n",
            "'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n",
            "\n",
            "AIMessage(content='There are 5 letters in the word \"educa\".')],\n",
            "\n",
            "'output': 'No, \"educa\" is not a real word in English.'}\n",
            "\n",
            "Here’s the LangSmith trace:\n",
            "https://smith.langchain.com/public/1e1b7e07-3220-4a6c-8a1e-f04182a755b3/r\n",
            "\n",
            "Next Steps​\n",
            "\n",
            "Awesome! You’ve now run your first end-to-end agent. To dive deeper, you\n",
            "can:\n",
            "\n",
            "Check out all the different agent\n",
            "types supported\n",
            "\n",
            "Learn all the controls for\n",
            "AgentExecutor\n",
            "\n",
            "Explore the how-to’s of tools and all\n",
            "the tool integrations\n",
            "\n",
            "See a full list of all the off-the-shelf\n",
            "toolkits we provide\n",
            "\n",
            "PreviousIndexing\n",
            "\n",
            "NextAgent Types\n",
            "\n",
            "ConceptsAgentToolsToolkitsAgentExecutorOther types of agent runtimes\n",
            "\n",
            "Get startedSetup: LangSmithDefine the agentDefine the runtimeUsing AgentExecutorAdding memory\n",
            "\n",
            "Next Steps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 3000\n",
        "chunk_overlap = 200\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    # separator = \"\\n\\n\"\n",
        "  chunk_size=chunk_size, # Maximum size of a chunk\n",
        "  chunk_overlap=chunk_overlap, # Maintain continuity, have some overlap of chunks\n",
        "  length_function=len, # Count number of characters to measure chunk size\n",
        ")\n",
        "texts = text_splitter.split_text( data[0].page_content)\n",
        "\n",
        "# Create Document objects for each text chunk\n",
        "docs = [Document(page_content=t) for t in texts[:]]"
      ],
      "metadata": {
        "id": "fO_sb88_MhYL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsCqMI1uMS00",
        "outputId": "ba2dfb7e-b4a1-441a-e28e-959a66e39be5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzLzYuOlMlZD",
        "outputId": "38dbddd0-0f4e-4f33-a007-da5414e7bdd3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modules\n",
            "\n",
            "Agents\n",
            "\n",
            "Agents\n",
            "\n",
            "The core idea of agents is to use a language model to choose a sequence\n",
            "of actions to take. In chains, a sequence of actions is hardcoded (in\n",
            "code). In agents, a language model is used as a reasoning engine to\n",
            "determine which actions to take and in which order.\n",
            "\n",
            "Concepts​\n",
            "\n",
            "There are several key components here:\n",
            "\n",
            "Agent​\n",
            "\n",
            "This is the chain responsible for deciding what step to take next. This\n",
            "is powered by a language model and a prompt. The inputs to this chain\n",
            "are:\n",
            "\n",
            "Tools: Descriptions of available tools\n",
            "\n",
            "User input: The high level objective\n",
            "\n",
            "Intermediate steps: Any (action, tool output) pairs previously\n",
            "executed in order to achieve the user input\n",
            "\n",
            "The output is the next action(s) to take or the final response to send\n",
            "to the user (AgentActions or AgentFinish). An action specifies a\n",
            "tool and the input to that tool.\n",
            "\n",
            "Different agents have different prompting styles for reasoning,\n",
            "different ways of encoding inputs, and different ways of parsing the\n",
            "output. For a full list of built-in agents see agent\n",
            "types. You can also easily build\n",
            "custom agents, which we show how to do in the Get started section\n",
            "below.\n",
            "\n",
            "Tools​\n",
            "\n",
            "Tools are functions that an agent can invoke. There are two important\n",
            "design considerations around tools:\n",
            "\n",
            "Giving the agent access to the right tools\n",
            "\n",
            "Describing the tools in a way that is most helpful to the agent\n",
            "\n",
            "Without thinking through both, you won’t be able to build a working\n",
            "agent. If you don’t give the agent access to a correct set of tools, it\n",
            "will never be able to accomplish the objectives you give it. If you\n",
            "don’t describe the tools well, the agent won’t know how to use them\n",
            "properly.\n",
            "\n",
            "LangChain provides a wide set of built-in tools, but also makes it easy\n",
            "to define your own (including custom descriptions). For a full list of\n",
            "built-in tools, see the tools integrations\n",
            "section\n",
            "\n",
            "Toolkits​\n",
            "\n",
            "For many common tasks, an agent will need a set of related tools. For\n",
            "this LangChain provides the concept of toolkits - groups of around 3-5\n",
            "tools needed to accomplish specific objectives. For example, the GitHub\n",
            "toolkit has a tool for searching through GitHub issues, a tool for\n",
            "reading a file, a tool for commenting, etc.\n",
            "\n",
            "LangChain provides a wide set of toolkits to get started. For a full\n",
            "list of built-in toolkits, see the toolkits integrations\n",
            "section\n",
            "\n",
            "AgentExecutor​\n",
            "\n",
            "The agent executor is the runtime for an agent. This is what actually\n",
            "calls the agent, executes the actions it chooses, passes the action\n",
            "outputs back to the agent, and repeats. In pseudocode, this looks\n",
            "roughly like:\n",
            "\n",
            "next_action\n",
            "\n",
            "agent\n",
            "\n",
            "get_action\n",
            "\n",
            "while\n",
            "\n",
            "next_action\n",
            "\n",
            "!=\n",
            "\n",
            "AgentFinish\n",
            "\n",
            "observation\n",
            "\n",
            "run\n",
            "\n",
            "next_action\n",
            "\n",
            "next_action\n",
            "\n",
            "agent\n",
            "\n",
            "get_action\n",
            "\n",
            "next_action\n",
            "\n",
            "observation\n",
            "\n",
            "return\n",
            "\n",
            "next_action\n",
            "\n",
            "While this may seem simple, there are several complexities this runtime\n",
            "handles for you, including:\n",
            "\n",
            "Handling cases where the agent selects a non-existent tool\n",
            "\n",
            "Handling cases where the tool errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key =  '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'\n",
        "print(openai.api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuBnx8-xMp2Y",
        "outputId": "59d5fc93-d010-4704-f4a5-61f13ade174f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key = openai.api_key)"
      ],
      "metadata": {
        "id": "OHL6sR53MyFn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# To summarize multiple documents\n",
        "# chain = \"map_reduce\" - find summary for each Document and then summarize all summaries\n",
        "map_reduce_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")"
      ],
      "metadata": {
        "id": "GvqHoqs4M0Hd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform summarization using run\n",
        "# docs - list of documents to summarize\n",
        "output = map_reduce_chain.run(docs)\n",
        "# install tiktoken"
      ],
      "metadata": {
        "id": "0wvBK8f9M2xr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM6J41b7Nh7t",
        "outputId": "6326af81-7eb4-4f7a-c220-5a934fd54334"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " This article provides an overview of agents, a language model used to choose a sequence of actions, and how to create a custom agent using OpenAI Function Calling. It covers the AgentExecutor class, tools, toolkits, and LangSmith for debugging and observability. It also explains how to create an agent that can remember previous interactions and answer follow-up questions.\n"
          ]
        }
      ]
    }
  ]
}